{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "print('Libraries Imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (150, 5)\n",
      "   sepal length in cm  sepal width in cm  petal length in cm  \\\n",
      "0                 5.1                3.5                 1.4   \n",
      "1                 4.9                3.0                 1.4   \n",
      "2                 4.7                3.2                 1.3   \n",
      "3                 4.6                3.1                 1.5   \n",
      "4                 5.0                3.6                 1.4   \n",
      "\n",
      "   petal width in cm      species  \n",
      "0                0.2  Iris-setosa  \n",
      "1                0.2  Iris-setosa  \n",
      "2                0.2  Iris-setosa  \n",
      "3                0.2  Iris-setosa  \n",
      "4                0.2  Iris-setosa  \n"
     ]
    }
   ],
   "source": [
    "#Creating Dataset and including the first row by setting no header as input\n",
    "dataset = pd.read_csv('data/iris.data.csv', header = None)\n",
    "#Renaming the columns\n",
    "dataset.columns = ['sepal length in cm', 'sepal width in cm','petal length in cm','petal width in cm','species']\n",
    "print('Shape of the dataset: ' + str(dataset.shape))\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: species, dtype: int64\n",
      "Index(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Creating the dependent variable class\n",
    "factor = pd.factorize(dataset['species'])\n",
    "dataset.species = factor[0]\n",
    "definitions = factor[1]\n",
    "print(dataset.species.head())\n",
    "print(definitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The independent features set: \n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "The dependent variable: \n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data into independent and dependent variables\n",
    "X = dataset.iloc[:,0:4].values\n",
    "y = dataset.iloc[:,4].values\n",
    "print('The independent features set: ')\n",
    "print(X[:5,:])\n",
    "print('The dependent variable: ')\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Training and Test set from data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0             0   1   2\n",
      "row_0                      \n",
      "Iris-setosa      13   0   0\n",
      "Iris-versicolor   0  12   3\n",
      "Iris-virginica    0   0  10\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "#Reverse factorize (converting y_pred from 0s,1s and 2s to Iris-setosa, Iris-versicolor and Iris-virginica\n",
    "reversefactor = dict(zip(range(3),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Actual Species'], colnames=['Predicted Species']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
